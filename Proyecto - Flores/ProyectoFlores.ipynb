{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9e3521-eb1e-43a2-8c0b-5c9e20504876",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '../input/flowers-recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/flowers-recognition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: '../input/flowers-recognition'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/flowers-recognition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04a929-3d2a-400b-8ee2-7189be2dcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../input/flowers-recognition/flowers/flowers\"\n",
    "folders = os.listdir(data)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458e225-d87f-45af-a4ad-8c4e7944adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "image_names = []\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "size = 120,120\n",
    "\n",
    "for folder in folders:\n",
    "    for file in tqdm(os.listdir(os.path.join(data,folder))):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            image_names.append(os.path.join(data,folder,file))\n",
    "            train_labels.append(folder)\n",
    "            img = cv2.imread(os.path.join(data,folder,file))\n",
    "            im = cv2.resize(img,size)\n",
    "            train_images.append(im)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0522a-ca23-42b1-a2bb-95cf734e7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(train_images)\n",
    "\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abde5db-b686-48b1-952e-e0cbee2d8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(train_labels)\n",
    "Y=to_categorical(Y,5)\n",
    "X=np.array(X1)\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d6f02-03f7-4fc0-9ac1-6c80af2aca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e82f8-1157-4c40-a1a4-b62c3db08fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.20, random_state=42)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc31a5a-7f56-42d1-9a35-9a0a613b038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for i in range(10,100,20):\n",
    "    plt.imshow(X_train[i][:,:,0],cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19369a4e-dcb7-41c6-b877-77d8881f2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70333c35-a980-4c39-89c6-18363df31730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'valid', \n",
    "                 activation ='relu', input_shape = (120,120,3)))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3),padding = 'valid', \n",
    "                 activation ='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Conv2D(filters = 160, kernel_size = (3,3),padding = 'valid',\n",
    "                 activation ='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 192, kernel_size = (3,3),padding = 'valid',\n",
    "                 activation ='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'valid',\n",
    "                 activation ='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36175e2-c525-4d25-8516-e6dfd9320ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d0ee3-2ce5-444e-b0ea-1951dd9e4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdee2df-82db-4e92-89e6-41ffd7a02463",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db0ee7-d612-409f-bf3a-43c0dc5b3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False, \n",
    "        rotation_range=10, \n",
    "        zoom_range = 0.8,\n",
    "        width_shift_range=0.8,  \n",
    "        height_shift_range=0.8,  \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False)  \n",
    "\n",
    "datagen.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6870202-75a6-434f-ab68-a172525af394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf583490-c799-495a-80a9-f0ef4402b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train,Y_train, batch_size=batch_size, epochs = epochs, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4eff2e-3b47-4e05-a6e8-a2140f273c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "\n",
    "def guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos):\n",
    "    print(\"Guardando Red Neuronal en Archivo\")  \n",
    "    # serializar modelo a JSON\n",
    "\n",
    "    # Guardar los Pesos (weights)\n",
    "    model.save_weights(nombreArchivoPesos+'.h5')\n",
    "\n",
    "    # Guardar la Arquitectura del modelo\n",
    "    with open(nombreArchivoModelo+'.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    print(\"Red Neuronal Grabada en Archivo\")   \n",
    "    \n",
    "def cargarRNN(nombreArchivoModelo,nombreArchivoPesos):\n",
    "        \n",
    "    # Cargar la Arquitectura desde el archivo JSON\n",
    "    with open(nombreArchivoModelo+'.json', 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    # Cargar Pesos (weights) en el nuevo modelo\n",
    "    model.load_weights(nombreArchivoPesos+'.h5')  \n",
    "\n",
    "    print(\"Red Neuronal Cargada desde Archivo\") \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895ebec-4f60-4acf-bd22-9ffc2e071d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, verbose=0)\n",
    "model.summary()\n",
    "print('Resultado en Train:')\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "#Fase de Testing\n",
    "print('Resultado en Test:')\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "nombreArchivoModelo='arquitectura_base'\n",
    "nombreArchivoPesos='pesos_base'\n",
    "guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0d23d-24cb-4e54-b023-26fc6615f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "IMG_SIZE=150\n",
    "FLOWER_DAISY_DIR='../input/flowers-recognition/flowers/daisy'\n",
    "FLOWER_SUNFLOWER_DIR='../input/flowers-recognition/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR='../input/flowers-recognition/flowers/tulip'\n",
    "FLOWER_DANDI_DIR='../input/flowers-recognition/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR='../input/flowers-recognition/flowers/rose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf136b-5f54-4b69-a701-14ca0c46c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(img,flower_type):\n",
    "    return flower_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d688521-88e8-4bcd-9c19-db07fa603cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(flower_type,DIR):\n",
    "    for img in tqdm(os.listdir(DIR)):\n",
    "        label=assign_label(img,flower_type)\n",
    "        path = os.path.join(DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "        X.append(np.array(img))\n",
    "        Z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ec69c-b57d-4891-9873-351b26056d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_data('Daisy',FLOWER_DAISY_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b972ef7-3cd8-4a14-bb72-b187ccdeffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50354fe2-ea19-4423-9e33-1a4889604479",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_data('Tulip',FLOWER_TULIP_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ddb3c-2a7a-41e4-b868-984801d014d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_data('Rose',FLOWER_ROSE_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b3326-d962-4d37-a200-2c98ad0cd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(5,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range(5):\n",
    "    for j in range (2):\n",
    "        l=rn.randint(0,len(Z))\n",
    "        ax[i,j].imshow(X[l])\n",
    "        ax[i,j].set_title('Flower: '+Z[l])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8f679-879e-460f-888f-babdd3f524a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Z)\n",
    "Y=to_categorical(Y,5)\n",
    "X=np.array(X)\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e180d4-e845-4520-9889-d71b1597095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "\n",
    "def guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos):\n",
    "    print(\"Guardando Red Neuronal en Archivo\")  \n",
    "    # serializar modelo a JSON\n",
    "\n",
    "    # Guardar los Pesos (weights)\n",
    "    model.save_weights(nombreArchivoPesos+'.h5')\n",
    "\n",
    "    # Guardar la Arquitectura del modelo\n",
    "    with open(nombreArchivoModelo+'.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    print(\"Red Neuronal Grabada en Archivo\")   \n",
    "    \n",
    "def cargarRNN(nombreArchivoModelo,nombreArchivoPesos):\n",
    "        \n",
    "    # Cargar la Arquitectura desde el archivo JSON\n",
    "    with open(nombreArchivoModelo+'.json', 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    # Cargar Pesos (weights) en el nuevo modelo\n",
    "    model.load_weights(nombreArchivoPesos+'.h5')  \n",
    "\n",
    "    print(\"Red Neuronal Cargada desde Archivo\") \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7c182-1d93-4339-b9d9-55e601cab47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984499b4-e075-4c6f-a736-ccb0ae8043fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027aec79-0b37-4f83-b520-d2af7171cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2989f3-ce5f-44d7-900e-94d7ce619e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=50\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59553f-535c-4be8-9965-d15332547ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, # establece la media de entrada a 0 sobre el conjunto de datos\n",
    "        samplewise_center=False,  # establece cada media de muestra en 0\n",
    "        featurewise_std_normalization=False, # dividir entradas por estándar del conjunto de datos \n",
    "        samplewise_std_normalization=False, # divide cada entrada por su estándar\n",
    "        zca_whitening=False,  # aplicar blanqueamiento ZCA\n",
    "        rotation_range=10,  # rotar imágenes al azar en el rango (grados, 0 a 180)\n",
    "        zoom_range = 0.1, # Ampliar aleatoriamente la imagen\n",
    "        width_shift_range=0.2, # mover imágenes al azar horizontalmente (fracción del ancho total) \n",
    "        height_shift_range=0.2, # mover imágenes al azar verticalmente (fracción de la altura total)\n",
    "        horizontal_flip=True, # voltear imágenes al azar\n",
    "        vertical_flip=False) # voltear imágenes al azar \n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281b2e7-e949-4808-aae9-7afcc9c4556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f7319-d483-4ae8-8da0-33aba522c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8a791-e5af-4b7c-9747-d2671ba761d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_test,y_test),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n",
    "model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506cab1-d226-4ab4-9552-44a173588369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar pesos y la arquitectura\n",
    "model2=cargarRNN(nombreArchivoModelo,nombreArchivoPesos) \n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method\n",
    "score = model2.evaluate(x_train, y_train, verbose=0)\n",
    "print('Resultado en Train:')\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
    "\n",
    "#Fase de Testing\n",
    "print('Resultado en Test:')\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
    "\n",
    "#Guardamos los archivos de modelo de pruebas\n",
    "nombreArchivoModelo='arquitectura_prueba'\n",
    "nombreArchivoPesos='pesos_prueba'\n",
    "guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3711cc5-d380-4999-91eb-670235b35604",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fd23e-3cbf-452d-90ee-637ac1f86fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5239e72-bea1-4558-822e-8b95ec4638e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obteniendo predicciones sobre el conjunto de valores.\n",
    "pred=model.predict(x_test)\n",
    "pred_digits=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca376f4b-b1b1-43fb-889b-52126bd372ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora almacena algunos índices correctamente y mal clasificados '.\n",
    "i=0\n",
    "prop_class=[]\n",
    "mis_class=[]\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if(np.argmax(y_test[i])==pred_digits[i]):\n",
    "        prop_class.append(i)\n",
    "    if(len(prop_class)==8):\n",
    "        break\n",
    "\n",
    "i=0\n",
    "for i in range(len(y_test)):\n",
    "    if(not np.argmax(y_test[i])==pred_digits[i]):\n",
    "        mis_class.append(i)\n",
    "    if(len(mis_class)==8):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f2bce-1248-4d6d-b14b-f657d64bfe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "count=0\n",
    "fig,ax=plt.subplots(4,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range (4):\n",
    "    for j in range (2):\n",
    "        ax[i,j].imshow(x_test[prop_class[count]])\n",
    "        ax[i,j].set_title(\"Predicted Flower :\"+str(le.inverse_transform([pred_digits[prop_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[prop_class[count]])])))\n",
    "        plt.tight_layout()\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e02c3f-7943-4b51-939d-3de7899947f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "count=0\n",
    "fig,ax=plt.subplots(4,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range (4):\n",
    "    for j in range (2):\n",
    "        ax[i,j].imshow(x_test[mis_class[count]])\n",
    "        ax[i,j].set_title(\"Predicted Flower :\"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n",
    "        plt.tight_layout()\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151ea5c-fa95-4f3c-b390-0a2b4c502bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(x_train,y_train, batch_size=batch_size, epochs = epochs, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d99ee8-655a-4286-9f26-e4ae8c8c3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Compilación: Prueba de mejores parámetros batch_size, epochs y optimizer\n",
    "#Esto recomiendo probarlo con Google Colab, puesto que se necesita 16GB en RAM y puede llegar a tardar unos 30min.\n",
    "\n",
    "def build_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#parámetros que queremos probar, y sus valores \n",
    "#probaremos con batch_size, epochs, y optimizador, con el fin de encontrar la mejor combinación entre estos tres parámetros.\n",
    "parameters = parameters = {'batch_size': [16,32],\n",
    "             'epochs':[100,500],\n",
    "             'optimizer': ['adadelta', 'rmsprop']}\n",
    "\n",
    "estimator = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "#Ahora no le pasamos los parámetros al KerasClasifier, porque se los pasaremos a través de GridSearchCV\n",
    "#el argumento verbose=0 es para que no muestre salida, si lo dejamos en cero, no mostrará la barra de progreso del entrenamiento\n",
    "#GridSearchCV: recibe como parámetros nuestro modelo, nuestros parámetros, la medida sobre la que queremos comparar, y la \n",
    "#cantidad de veces que lo entrenará para sacar la media de accuracy.\n",
    "grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='accuracy', cv=10,n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "#grid_search.best_params_\n",
    "print(grid_search.best_params_)\n",
    "#Un ejemplo de resultados es: {'batch_size': 16, 'epochs': 100, 'optimizer': 'rmsprop'}\n",
    "#Esto indica que el optimizador \"adadelta\" no es adecuado. Y es que este optimizador NO sirve para este tipo de problemas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
